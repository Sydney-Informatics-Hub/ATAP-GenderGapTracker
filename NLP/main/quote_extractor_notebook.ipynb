{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c2662a3",
   "metadata": {},
   "source": [
    "# Quote Extractor\n",
    "In this notebook, we will use the *Quote Extractor* tool to extract quotes from a list of texts. In addition to extracting the quotes, the tool provides information about who the speaker is, the location of the quote (and the speaker) in the text.  \n",
    "\n",
    "**Note:** This code has been adapted from the [GenderGapTracker](https://github.com/sfu-discourse-lab/GenderGapTracker/tree/master/NLP/main) GitHub page and modified to run on a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99ca86",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Before we begin, we need to import the necessary tools and packages for our tool to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189dd6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sjuf9909/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "# pandas: tools for data processing\n",
    "import pandas as pd\n",
    "\n",
    "# spaCy and NLTK: natural language processing tools for working with language/text data\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import Tree\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# import the quote extractor tool\n",
    "from quote_extractor import extract_quotes, get_rawtext_files\n",
    "from config import config\n",
    "import utils\n",
    "\n",
    "# initiate the app_logger\n",
    "app_logger = utils.create_logger('quote_extractor', log_dir='logs', logger_level=logging.INFO, \n",
    "                                 file_log_level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3acbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spaCy language model...\n",
      "Finished loading.\n"
     ]
    }
   ],
   "source": [
    "# download spaCy's en_core_web_lg, the pre-trained English language tool from spaCy\n",
    "print('Loading spaCy language model...')\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "print('Finished loading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf517c9",
   "metadata": {},
   "source": [
    "## 2. Load the data\n",
    "This notebook will allow you to extract quotes directly from a text file (or a number of text files). Alternatively, you can also extract quotes from a text column inside your excel spreadsheet, if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfba236e",
   "metadata": {},
   "source": [
    "### 2.1. From a text file\n",
    "In order to extract quotes directly from a text file, you need to store all your text files (.txt) in a folder on your computer, e.g., we use the 'input' folder in the below example. Using the below code, we will access those files and extract the text into a pandas dataframe (in table format) for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "200494c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test2</td>\n",
       "      <td>(CBC News)\\n\\nRepublican lawmakers and previou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test3</td>\n",
       "      <td>Federated States of Micronesia President David...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_id                                               text\n",
       "0   test1  Facebook and Instagram, which Facebook owns, f...\n",
       "1   test2  (CBC News)\\n\\nRepublican lawmakers and previou...\n",
       "2   test3  Federated States of Micronesia President David..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify the file path to the folder you use to store your text files\n",
    "file_path = './input/'\n",
    "\n",
    "# create an empty list for a placeholder to store all the texts\n",
    "all_files = []\n",
    "\n",
    "# search for text files (.txt) inside the folder and extract all the texts\n",
    "for input_file in get_rawtext_files(file_path):\n",
    "    text_dict = {}\n",
    "    \n",
    "    # use the text file name as the doc_id\n",
    "    doc_id = input_file.replace('.txt', '')\n",
    "    \n",
    "    try:\n",
    "        # read the text file\n",
    "        doc_lines = open(os.path.join(file_path, input_file), 'r').readlines()\n",
    "        doc_lines = '\\n'.join(doc_lines)\n",
    "        \n",
    "        # store them inside a dictionary\n",
    "        text_dict['text_id'] = doc_id\n",
    "        text_dict['text'] = doc_lines\n",
    "        all_files.append(text_dict)\n",
    "            \n",
    "    except:\n",
    "        # this will provide some information in the case of an error\n",
    "        app_logger.exception(\"message\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "# convert the extracted texts into a pandas dataframe for further processing\n",
    "text_df = pd.DataFrame.from_dict(all_files)\n",
    "new_index = ['text_id', 'text']\n",
    "text_df = text_df.reindex(columns=new_index)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4802e6",
   "metadata": {},
   "source": [
    "### 2.2. From an Excel spreadsheet\n",
    "If you have already stored your texts in an Excel spreadsheet, you can use the below code to access your spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13998266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text2</td>\n",
       "      <td>(CBC News)\\nRepublican lawmakers and previous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text3</td>\n",
       "      <td>Federated States of Micronesia President David...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_id                                               text\n",
       "0   text1  Facebook and Instagram, which Facebook owns, f...\n",
       "1   text2  (CBC News)\\nRepublican lawmakers and previous ...\n",
       "2   text3  Federated States of Micronesia President David..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter the file path and the file name of the excel spreadsheet containing the text\n",
    "file_path = './input/'\n",
    "file_name = 'text_files.xlsx'\n",
    "\n",
    "# read the pandas dataframe containing the list of texts\n",
    "text_df = pd.read_excel(file_path + file_name)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4039347d",
   "metadata": {},
   "source": [
    "## 3. Extract the quotes\n",
    "Once your texts have been stored in a pandas dataframe, we can begin to extract the quotes from the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96151dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the column name containing the text\n",
    "text_col_name = 'text'\n",
    "\n",
    "# specify whether you wish to create a parse tree for the quotes \n",
    "# you also need to specify the output file path if 'True'\n",
    "write_quote_trees_in_file = True #False\n",
    "tree_dir = './output/trees/'\n",
    "\n",
    "# create an empty list to store all detected quotes\n",
    "all_quotes = []\n",
    "\n",
    "# go through all the texts and start extracting quotes\n",
    "for n, text in enumerate(text_df[text_col_name]):\n",
    "    doc_id = text_df['text_id'][n]\n",
    "    \n",
    "    try:\n",
    "        # pre-process the text\n",
    "        text = sent_tokenize(text)\n",
    "        text = ' '.join(text)\n",
    "        text = utils.preprocess_text(text)\n",
    "        \n",
    "        # apply the spaCy's tool to the text\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        # extract the quotes\n",
    "        quotes = extract_quotes(doc_id=doc_id, doc=doc, \n",
    "                                write_tree=write_quote_trees_in_file, \n",
    "                                tree_dir=tree_dir)\n",
    "        \n",
    "        # add quote_id to each quote\n",
    "        for n, quote in enumerate(quotes):\n",
    "            quote['text_id'] = doc_id\n",
    "            quote['quote_id'] = str(n)\n",
    "            quote['text'] = text\n",
    "            quote['text_spacy'] = doc\n",
    "        \n",
    "        # store them in all_quotes\n",
    "        all_quotes.extend(quotes)\n",
    "            \n",
    "    except:\n",
    "        # this will provide some information in the case of an error\n",
    "        app_logger.exception(\"message\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be6223",
   "metadata": {},
   "source": [
    "## 4. Display the quotes\n",
    "Once you are have extracted the quotes, we will store them in a pandas dataframe for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1df10d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>quote_id</th>\n",
       "      <th>quote</th>\n",
       "      <th>quote_index</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_index</th>\n",
       "      <th>verb</th>\n",
       "      <th>verb_index</th>\n",
       "      <th>quote_token_count</th>\n",
       "      <th>quote_type</th>\n",
       "      <th>is_floating_quote</th>\n",
       "      <th>text_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "      <td>0</td>\n",
       "      <td>\"We didn't just see a breach at the Capitol. S...</td>\n",
       "      <td>(1052, 1238)</td>\n",
       "      <td>Grygiel</td>\n",
       "      <td>(1239, 1246)</td>\n",
       "      <td>said</td>\n",
       "      <td>(1247, 1251)</td>\n",
       "      <td>38</td>\n",
       "      <td>Heuristic</td>\n",
       "      <td>False</td>\n",
       "      <td>(Facebook, and, Instagram, ,, which, Facebook,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Social media is complicit in this because he ...</td>\n",
       "      <td>(1492, 1691)</td>\n",
       "      <td></td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>caused</td>\n",
       "      <td>(1705, 1711)</td>\n",
       "      <td>39</td>\n",
       "      <td>Heuristic</td>\n",
       "      <td>False</td>\n",
       "      <td>(Facebook, and, Instagram, ,, which, Facebook,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "      <td>2</td>\n",
       "      <td>that Trump wouldn't be able to post for 24 hou...</td>\n",
       "      <td>(84, 173)</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns,</td>\n",
       "      <td>(0, 44)</td>\n",
       "      <td>announcing</td>\n",
       "      <td>(73, 83)</td>\n",
       "      <td>17</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "      <td>(Facebook, and, Instagram, ,, which, Facebook,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "      <td>3</td>\n",
       "      <td>that these actions follow years of hemming and...</td>\n",
       "      <td>(302, 489)</td>\n",
       "      <td>experts</td>\n",
       "      <td>(288, 295)</td>\n",
       "      <td>noted</td>\n",
       "      <td>(296, 301)</td>\n",
       "      <td>26</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "      <td>(Facebook, and, Instagram, ,, which, Facebook,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "      <td>4</td>\n",
       "      <td>what happened in Washington, D.C., on Wednesda...</td>\n",
       "      <td>(592, 813)</td>\n",
       "      <td>Jennifer Grygiel, a Syracuse University commun...</td>\n",
       "      <td>(491, 586)</td>\n",
       "      <td>said</td>\n",
       "      <td>(587, 591)</td>\n",
       "      <td>38</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "      <td>(Facebook, and, Instagram, ,, which, Facebook,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "      <td>5</td>\n",
       "      <td>\\n \"This is what happens</td>\n",
       "      <td>(1012, 1035)</td>\n",
       "      <td>Grygiel</td>\n",
       "      <td>(1038, 1045)</td>\n",
       "      <td>said</td>\n",
       "      <td>(1046, 1050)</td>\n",
       "      <td>6</td>\n",
       "      <td>C S V</td>\n",
       "      <td>False</td>\n",
       "      <td>(Facebook, and, Instagram, ,, which, Facebook,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>text1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "      <td>6</td>\n",
       "      <td>They're creeping along towards firmer action</td>\n",
       "      <td>(1352, 1396)</td>\n",
       "      <td>Grygiel</td>\n",
       "      <td>(1399, 1406)</td>\n",
       "      <td>said</td>\n",
       "      <td>(1407, 1411)</td>\n",
       "      <td>7</td>\n",
       "      <td>Q C Q S V</td>\n",
       "      <td>False</td>\n",
       "      <td>(Facebook, and, Instagram, ,, which, Facebook,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>text1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "      <td>7</td>\n",
       "      <td>that the video was removed because it \"contrib...</td>\n",
       "      <td>(2362, 2467)</td>\n",
       "      <td>Guy Rosen, Facebook's vice-president of integr...</td>\n",
       "      <td>(2285, 2335)</td>\n",
       "      <td>said</td>\n",
       "      <td>(2336, 2340)</td>\n",
       "      <td>18</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "      <td>(Facebook, and, Instagram, ,, which, Facebook,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>text1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "      <td>8</td>\n",
       "      <td>This is an emergency situation and we are taki...</td>\n",
       "      <td>(2471, 2594)</td>\n",
       "      <td>Rosen</td>\n",
       "      <td>(2597, 2602)</td>\n",
       "      <td>said</td>\n",
       "      <td>(2603, 2607)</td>\n",
       "      <td>19</td>\n",
       "      <td>Q C Q S V</td>\n",
       "      <td>False</td>\n",
       "      <td>(Facebook, and, Instagram, ,, which, Facebook,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>text1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "      <td>9</td>\n",
       "      <td>I know your pain</td>\n",
       "      <td>(2803, 2819)</td>\n",
       "      <td>his video</td>\n",
       "      <td>(2784, 2793)</td>\n",
       "      <td>saying</td>\n",
       "      <td>(2794, 2800)</td>\n",
       "      <td>4</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "      <td>(Facebook, and, Instagram, ,, which, Facebook,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>text1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "      <td>10</td>\n",
       "      <td>We can't play into the hands of these people</td>\n",
       "      <td>(2963, 3007)</td>\n",
       "      <td>Trump</td>\n",
       "      <td>(2940, 2945)</td>\n",
       "      <td>say</td>\n",
       "      <td>(2957, 2960)</td>\n",
       "      <td>10</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "      <td>(Facebook, and, Instagram, ,, which, Facebook,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>text2</td>\n",
       "      <td>(CBC News).\\n Republican lawmakers and previou...</td>\n",
       "      <td>0</td>\n",
       "      <td>\"More than anything, what is happening right n...</td>\n",
       "      <td>(847, 1017)</td>\n",
       "      <td></td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>33</td>\n",
       "      <td>Heuristic</td>\n",
       "      <td>False</td>\n",
       "      <td>((, CBC, News, ), ., \\n , Republican, lawmaker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>text2</td>\n",
       "      <td>(CBC News).\\n Republican lawmakers and previou...</td>\n",
       "      <td>1</td>\n",
       "      <td>Canadians 'deeply disturbed' by violence in Wa...</td>\n",
       "      <td>(437, 496)</td>\n",
       "      <td>Trudeau</td>\n",
       "      <td>(424, 431)</td>\n",
       "      <td>says</td>\n",
       "      <td>(432, 436)</td>\n",
       "      <td>10</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "      <td>((, CBC, News, ), ., \\n , Republican, lawmaker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>text2</td>\n",
       "      <td>(CBC News).\\n Republican lawmakers and previou...</td>\n",
       "      <td>2</td>\n",
       "      <td>\\n Trump has harnessed social media — especial...</td>\n",
       "      <td>(496, 618)</td>\n",
       "      <td>Trudeau</td>\n",
       "      <td>(424, 431)</td>\n",
       "      <td>says</td>\n",
       "      <td>(432, 436)</td>\n",
       "      <td>20</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "      <td>((, CBC, News, ), ., \\n , Republican, lawmaker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>text2</td>\n",
       "      <td>(CBC News).\\n Republican lawmakers and previou...</td>\n",
       "      <td>3</td>\n",
       "      <td>\"The President has promoted sedition and incit...</td>\n",
       "      <td>(690, 747)</td>\n",
       "      <td>Jonathan Greenblatt, chief executive officer o...</td>\n",
       "      <td>(755, 830)</td>\n",
       "      <td>said</td>\n",
       "      <td>(750, 754)</td>\n",
       "      <td>9</td>\n",
       "      <td>Q C Q V S</td>\n",
       "      <td>False</td>\n",
       "      <td>((, CBC, News, ), ., \\n , Republican, lawmaker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>text2</td>\n",
       "      <td>(CBC News).\\n Republican lawmakers and previou...</td>\n",
       "      <td>4</td>\n",
       "      <td>there would be an \"orderly transition on Janua...</td>\n",
       "      <td>(1062, 1175)</td>\n",
       "      <td>Trump</td>\n",
       "      <td>(1051, 1056)</td>\n",
       "      <td>said</td>\n",
       "      <td>(1057, 1061)</td>\n",
       "      <td>21</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "      <td>((, CBC, News, ), ., \\n , Republican, lawmaker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>text3</td>\n",
       "      <td>Federated States of Micronesia President David...</td>\n",
       "      <td>0</td>\n",
       "      <td>the deal could stoke geopolitical tensions and...</td>\n",
       "      <td>(62, 149)</td>\n",
       "      <td>Federated States of Micronesia President David...</td>\n",
       "      <td>(0, 54)</td>\n",
       "      <td>warned</td>\n",
       "      <td>(55, 61)</td>\n",
       "      <td>13</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "      <td>(Federated, States, of, Micronesia, President,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>text3</td>\n",
       "      <td>Federated States of Micronesia President David...</td>\n",
       "      <td>1</td>\n",
       "      <td>the process had been rushed</td>\n",
       "      <td>(213, 240)</td>\n",
       "      <td>Samoa's Prime Minister, Fiame Naomi Mata'afa,</td>\n",
       "      <td>(157, 202)</td>\n",
       "      <td>suggested</td>\n",
       "      <td>(203, 212)</td>\n",
       "      <td>5</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "      <td>(Federated, States, of, Micronesia, President,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>text3</td>\n",
       "      <td>Federated States of Micronesia President David...</td>\n",
       "      <td>2</td>\n",
       "      <td>\"very little\" was currently known about the me...</td>\n",
       "      <td>(305, 356)</td>\n",
       "      <td>Pacific expert Anna Powles from Massey University</td>\n",
       "      <td>(242, 291)</td>\n",
       "      <td>told</td>\n",
       "      <td>(292, 296)</td>\n",
       "      <td>10</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "      <td>(Federated, States, of, Micronesia, President,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>text3</td>\n",
       "      <td>Federated States of Micronesia President David...</td>\n",
       "      <td>3</td>\n",
       "      <td>It appears to be an attempt to deliberately di...</td>\n",
       "      <td>(432, 541)</td>\n",
       "      <td>she</td>\n",
       "      <td>(544, 547)</td>\n",
       "      <td>said</td>\n",
       "      <td>(548, 552)</td>\n",
       "      <td>19</td>\n",
       "      <td>Q C Q S V</td>\n",
       "      <td>False</td>\n",
       "      <td>(Federated, States, of, Micronesia, President,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text quote_id  \\\n",
       "0    text1  Facebook and Instagram, which Facebook owns, f...        0   \n",
       "1    text1  Facebook and Instagram, which Facebook owns, f...        1   \n",
       "2    text1  Facebook and Instagram, which Facebook owns, f...        2   \n",
       "3    text1  Facebook and Instagram, which Facebook owns, f...        3   \n",
       "4    text1  Facebook and Instagram, which Facebook owns, f...        4   \n",
       "5    text1  Facebook and Instagram, which Facebook owns, f...        5   \n",
       "6    text1  Facebook and Instagram, which Facebook owns, f...        6   \n",
       "7    text1  Facebook and Instagram, which Facebook owns, f...        7   \n",
       "8    text1  Facebook and Instagram, which Facebook owns, f...        8   \n",
       "9    text1  Facebook and Instagram, which Facebook owns, f...        9   \n",
       "10   text1  Facebook and Instagram, which Facebook owns, f...       10   \n",
       "11   text2  (CBC News).\\n Republican lawmakers and previou...        0   \n",
       "12   text2  (CBC News).\\n Republican lawmakers and previou...        1   \n",
       "13   text2  (CBC News).\\n Republican lawmakers and previou...        2   \n",
       "14   text2  (CBC News).\\n Republican lawmakers and previou...        3   \n",
       "15   text2  (CBC News).\\n Republican lawmakers and previou...        4   \n",
       "16   text3  Federated States of Micronesia President David...        0   \n",
       "17   text3  Federated States of Micronesia President David...        1   \n",
       "18   text3  Federated States of Micronesia President David...        2   \n",
       "19   text3  Federated States of Micronesia President David...        3   \n",
       "\n",
       "                                                quote   quote_index  \\\n",
       "0   \"We didn't just see a breach at the Capitol. S...  (1052, 1238)   \n",
       "1   \"Social media is complicit in this because he ...  (1492, 1691)   \n",
       "2   that Trump wouldn't be able to post for 24 hou...     (84, 173)   \n",
       "3   that these actions follow years of hemming and...    (302, 489)   \n",
       "4   what happened in Washington, D.C., on Wednesda...    (592, 813)   \n",
       "5                            \\n \"This is what happens  (1012, 1035)   \n",
       "6        They're creeping along towards firmer action  (1352, 1396)   \n",
       "7   that the video was removed because it \"contrib...  (2362, 2467)   \n",
       "8   This is an emergency situation and we are taki...  (2471, 2594)   \n",
       "9                                    I know your pain  (2803, 2819)   \n",
       "10       We can't play into the hands of these people  (2963, 3007)   \n",
       "11  \"More than anything, what is happening right n...   (847, 1017)   \n",
       "12  Canadians 'deeply disturbed' by violence in Wa...    (437, 496)   \n",
       "13  \\n Trump has harnessed social media — especial...    (496, 618)   \n",
       "14  \"The President has promoted sedition and incit...    (690, 747)   \n",
       "15  there would be an \"orderly transition on Janua...  (1062, 1175)   \n",
       "16  the deal could stoke geopolitical tensions and...     (62, 149)   \n",
       "17                        the process had been rushed    (213, 240)   \n",
       "18  \"very little\" was currently known about the me...    (305, 356)   \n",
       "19  It appears to be an attempt to deliberately di...    (432, 541)   \n",
       "\n",
       "                                              speaker speaker_index  \\\n",
       "0                                             Grygiel  (1239, 1246)   \n",
       "1                                                            (0, 0)   \n",
       "2        Facebook and Instagram, which Facebook owns,       (0, 44)   \n",
       "3                                             experts    (288, 295)   \n",
       "4   Jennifer Grygiel, a Syracuse University commun...    (491, 586)   \n",
       "5                                             Grygiel  (1038, 1045)   \n",
       "6                                             Grygiel  (1399, 1406)   \n",
       "7   Guy Rosen, Facebook's vice-president of integr...  (2285, 2335)   \n",
       "8                                               Rosen  (2597, 2602)   \n",
       "9                                           his video  (2784, 2793)   \n",
       "10                                              Trump  (2940, 2945)   \n",
       "11                                                           (0, 0)   \n",
       "12                                            Trudeau    (424, 431)   \n",
       "13                                            Trudeau    (424, 431)   \n",
       "14  Jonathan Greenblatt, chief executive officer o...    (755, 830)   \n",
       "15                                              Trump  (1051, 1056)   \n",
       "16  Federated States of Micronesia President David...       (0, 54)   \n",
       "17      Samoa's Prime Minister, Fiame Naomi Mata'afa,    (157, 202)   \n",
       "18  Pacific expert Anna Powles from Massey University    (242, 291)   \n",
       "19                                                she    (544, 547)   \n",
       "\n",
       "          verb    verb_index  quote_token_count quote_type  is_floating_quote  \\\n",
       "0         said  (1247, 1251)                 38  Heuristic              False   \n",
       "1       caused  (1705, 1711)                 39  Heuristic              False   \n",
       "2   announcing      (73, 83)                 17      S V C              False   \n",
       "3        noted    (296, 301)                 26      S V C              False   \n",
       "4         said    (587, 591)                 38      S V C              False   \n",
       "5         said  (1046, 1050)                  6      C S V              False   \n",
       "6         said  (1407, 1411)                  7  Q C Q S V              False   \n",
       "7         said  (2336, 2340)                 18      S V C              False   \n",
       "8         said  (2603, 2607)                 19  Q C Q S V              False   \n",
       "9       saying  (2794, 2800)                  4      S V C              False   \n",
       "10         say  (2957, 2960)                 10      S V C              False   \n",
       "11                    (0, 0)                 33  Heuristic              False   \n",
       "12        says    (432, 436)                 10      S V C              False   \n",
       "13        says    (432, 436)                 20      S V C              False   \n",
       "14        said    (750, 754)                  9  Q C Q V S              False   \n",
       "15        said  (1057, 1061)                 21      S V C              False   \n",
       "16      warned      (55, 61)                 13      S V C              False   \n",
       "17   suggested    (203, 212)                  5      S V C              False   \n",
       "18        told    (292, 296)                 10      S V C              False   \n",
       "19        said    (548, 552)                 19  Q C Q S V              False   \n",
       "\n",
       "                                           text_spacy  \n",
       "0   (Facebook, and, Instagram, ,, which, Facebook,...  \n",
       "1   (Facebook, and, Instagram, ,, which, Facebook,...  \n",
       "2   (Facebook, and, Instagram, ,, which, Facebook,...  \n",
       "3   (Facebook, and, Instagram, ,, which, Facebook,...  \n",
       "4   (Facebook, and, Instagram, ,, which, Facebook,...  \n",
       "5   (Facebook, and, Instagram, ,, which, Facebook,...  \n",
       "6   (Facebook, and, Instagram, ,, which, Facebook,...  \n",
       "7   (Facebook, and, Instagram, ,, which, Facebook,...  \n",
       "8   (Facebook, and, Instagram, ,, which, Facebook,...  \n",
       "9   (Facebook, and, Instagram, ,, which, Facebook,...  \n",
       "10  (Facebook, and, Instagram, ,, which, Facebook,...  \n",
       "11  ((, CBC, News, ), ., \\n , Republican, lawmaker...  \n",
       "12  ((, CBC, News, ), ., \\n , Republican, lawmaker...  \n",
       "13  ((, CBC, News, ), ., \\n , Republican, lawmaker...  \n",
       "14  ((, CBC, News, ), ., \\n , Republican, lawmaker...  \n",
       "15  ((, CBC, News, ), ., \\n , Republican, lawmaker...  \n",
       "16  (Federated, States, of, Micronesia, President,...  \n",
       "17  (Federated, States, of, Micronesia, President,...  \n",
       "18  (Federated, States, of, Micronesia, President,...  \n",
       "19  (Federated, States, of, Micronesia, President,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the outcome into a pandas dataframe\n",
    "quotes_df = pd.DataFrame.from_dict(all_quotes)\n",
    "\n",
    "# convert the values in the index columns to a tuple\n",
    "for column in quotes_df.columns:\n",
    "    if column.endswith('_index'):\n",
    "        quotes_df[column].replace('','(0,0)', inplace=True)\n",
    "        quotes_df[column] = quotes_df[column].apply(eval)\n",
    "\n",
    "# re-arrange the columns\n",
    "new_index = ['text_id', 'text', 'quote_id', 'quote', 'quote_index', 'speaker', 'speaker_index', \n",
    "             'verb', 'verb_index', 'quote_token_count', 'quote_type', 'is_floating_quote', 'text_spacy']\n",
    "quotes_df = quotes_df.reindex(columns=new_index)\n",
    "\n",
    "# drop unused columns\n",
    "#quotes_df.drop(['quote_token_count', 'quote_type', 'is_floating_quote', 'verb', 'verb_index'], \n",
    "#               axis=1, inplace=True)\n",
    "       \n",
    "# preview the quotes dataframe\n",
    "quotes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feec27ad",
   "metadata": {},
   "source": [
    "In general, the quotes are extracted either based on syntactic rules or heuristic (custom) rules. Some quotes can be stand-alone in a sentence, or followed by another quote (floating quote) in the same sentence.   \n",
    "**Note:** *Q (Quotation mark), S (Speaker), V (Verb), C (Content)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e48e7fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It appears to be an attempt to deliberately disrupt existing regional mechanisms which China is not a part of'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_df['quote'][19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47a80e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[95].idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24dd48",
   "metadata": {},
   "source": [
    "We can show a preview of the quotes using spaCy's visualisation tool, displaCy. All you need to do is run the below function and specify the text_id you wish to analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da66a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = quotes_df[quotes_df['text_id']=='text3']['text_spacy'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6c016ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = [(432, 541)]\n",
    "\n",
    "loc2tok = [(t.idx, t.i) for t in doc]\n",
    "loc2tok_df = pd.DataFrame(loc2tok, columns = ['loc', 'token'])\n",
    "\n",
    "selTokens = []\n",
    "for span in spans:\n",
    "    temp = loc2tok_df.loc[(span[0]<=loc2tok_df['loc']) & (loc2tok_df['loc']<span[1]), 'token']\n",
    "    selTokens.append(temp.tolist())\n",
    "selTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795cb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0087dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "from spacy.tokens import Span\n",
    "\n",
    "# function to display the quotes and speakers in the text\n",
    "def show_quotes(text_id, save_to_html=True, out_dir='./output/'):\n",
    "    doc = quotes_df[quotes_df['text_id']==text_id]['text_spacy'].tolist()[0]\n",
    "    spans = [(432, 541)]\n",
    "\n",
    "    loc2tok_df = pd.DataFrame([(t.idx, t.i) for t in doc], columns = ['loc', 'token'])\n",
    "\n",
    "    selTokens = []\n",
    "\n",
    "    for span in spans:\n",
    "\n",
    "    temp = loc2tok_df.loc[(span[0]<=loc2tok_df['loc']) & (loc2tok_df['loc']<span[1]), 'token']\n",
    "\n",
    "    selTokens.append(temp.tolist())\n",
    "\n",
    "\n",
    "\n",
    "selTokens\n",
    "    # get the quotes and speakers indexes\n",
    "    locs = {\n",
    "        'QUOTE': quotes_df[quotes_df['text_id']==text_id]['quote_index'].tolist(),\n",
    "        'SPEAKER': set(quotes_df[quotes_df['text_id']==text_id]['speaker_index'].tolist())\n",
    "    }\n",
    "\n",
    "    # create displaCy code to visualise quotes and speakers \n",
    "    my_code_list = ['doc.spans[\"sc\"] = [', ']']\n",
    "    \n",
    "    for key in locs.keys():\n",
    "        for loc in locs[key]:\n",
    "            if loc!=(0,0):\n",
    "                start_token, end_token = selTokens[0], selTokens[-1]\n",
    "                #start_token = tokens[min(tokens.keys(), key=lambda x:abs(x-loc[0]))]\n",
    "                #end_token = tokens[min(tokens.keys(), key=lambda x:abs(x-loc[1]))]\n",
    "                span_code = \"Span(doc, {}, {}, '{}'),\".format(start_token,end_token, key)\n",
    "                my_code_list.insert(1,span_code)\n",
    "                \n",
    "    my_code = ''.join(my_code_list)\n",
    "\n",
    "    # formatting options\n",
    "    colors = {'QUOTE': '#7aecec', 'SPEAKER': '#bfeeb7'}\n",
    "    options = {'ents': ['QUOTE', 'SPEAKER'], \n",
    "               'colors': colors, 'top_offset': 31}\n",
    "\n",
    "    # execute the code\n",
    "    exec(my_code)\n",
    "\n",
    "    # option to save the preview as an html document\n",
    "    if save_to_html:\n",
    "        html = displacy.render(doc, style='span', options=options, jupyter=False, page=True)\n",
    "        \n",
    "        # save the quote preview into an html file\n",
    "        file = open(out_dir+text_id+'.html','w')\n",
    "        file.write(html)\n",
    "        file.close()\n",
    "    \n",
    "    # display the preview in this notebook\n",
    "    displacy.render(doc, style='span', options=options, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e238e391",
   "metadata": {},
   "source": [
    "By default, this function will also save the quote preview in an html file (with the text_id as the file name) inside the output directory. You can turn this option off by setting the *'save_to_html'* parameter to **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f815845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m/opt/anaconda3/envs/quote_display/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3397\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Input \u001b[1;32mIn [21]\u001b[0m in \u001b[1;35m<cell line: 5>\u001b[0m\n    show_quotes(text_id)\n",
      "\u001b[0;36m  Input \u001b[0;32mIn [20]\u001b[0;36m in \u001b[0;35mshow_quotes\u001b[0;36m\u001b[0m\n\u001b[0;31m    exec(my_code)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    doc.spans[\"sc\"] = [Span(doc, 76    76\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# specify the text_id\n",
    "text_id = 'text3'\n",
    "\n",
    "# display the quotes and the speakers in the text\n",
    "show_quotes(text_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3607fd4b",
   "metadata": {},
   "source": [
    "## 5. Save your quotes\n",
    "Finally, you can save the quote pandas dataframe into an Excel spreadsheet and download them on your local computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec7d0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save quotes_df into an Excel spreadsheet\n",
    "quotes_df.to_excel('./output/quotes.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
