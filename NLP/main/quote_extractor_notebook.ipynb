{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c2662a3",
   "metadata": {},
   "source": [
    "# Quote Extractor\n",
    "In this notebook, we will use the *Quote Extractor* tool to extract quotes from a list of texts. In addition to extracting the quotes, the tool provides information about who the speaker is, the location of the quote (and the speaker) in the text.  \n",
    "\n",
    "**Note:** This code has been adapted from the [GenderGapTracker](https://github.com/sfu-discourse-lab/GenderGapTracker/tree/master/NLP/main) GitHub page and modified to run on a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99ca86",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Before we begin, we need to import the necessary tools and packages for our tool to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189dd6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "# pandas: tools for data processing\n",
    "import pandas as pd\n",
    "\n",
    "# spaCy and NLTK: natural language processing tools for working with language/text data\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import Tree\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# import the quote extractor tool\n",
    "from quote_extractor import extract_quotes, get_rawtext_files\n",
    "from config import config\n",
    "import utils\n",
    "\n",
    "# initiate the app_logger\n",
    "app_logger = utils.create_logger('quote_extractor', log_dir='logs', logger_level=logging.INFO, \n",
    "                                 file_log_level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3acbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download spaCy's en_core_web_lg, the pre-trained English language tool from spaCy\n",
    "print('Loading spaCy language model...')\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "print('Finished loading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf517c9",
   "metadata": {},
   "source": [
    "## 2. Load the data\n",
    "This notebook will allow you to extract quotes directly from a text file (or a number of text files). Alternatively, you can also extract quotes from a text column inside your excel spreadsheet, if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfba236e",
   "metadata": {},
   "source": [
    "### 2.1. From a text file\n",
    "In order to extract quotes directly from a text file, you need to store all your text files (.txt) in a folder on your computer, e.g., we use the 'input' folder in the below example. Using the below code, we will access those files and extract the text into a pandas dataframe (in table format) for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751bf2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_preprocess(nlp, text):\n",
    "    # pre-process the text\n",
    "    text = sent_tokenize(text)\n",
    "    text = ' '.join(text)\n",
    "    text = utils.preprocess_text(text)\n",
    "    \n",
    "    # apply the spaCy's tool to the text\n",
    "    doc = nlp(text)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200494c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the file path to the folder you use to store your text files\n",
    "file_path = './input/'\n",
    "\n",
    "# create an empty list for a placeholder to store all the texts\n",
    "all_files = []\n",
    "\n",
    "# search for text files (.txt) inside the folder and extract all the texts\n",
    "for input_file in get_rawtext_files(file_path):\n",
    "    text_dict = {}\n",
    "    \n",
    "    # use the text file name as the doc_id\n",
    "    doc_id = input_file.replace('.txt', '')\n",
    "    \n",
    "    try:\n",
    "        # read the text file\n",
    "        doc_lines = open(os.path.join(file_path, input_file), 'r').readlines()\n",
    "        doc_lines = '\\n'.join(doc_lines)\n",
    "        \n",
    "        # store them inside a dictionary\n",
    "        text_dict['text_id'] = doc_id\n",
    "        text_dict['text'] = doc_lines\n",
    "        all_files.append(text_dict)\n",
    "            \n",
    "    except:\n",
    "        # this will provide some information in the case of an error\n",
    "        app_logger.exception(\"message\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "# convert the extracted texts into a pandas dataframe for further processing\n",
    "text_df = pd.DataFrame.from_dict(all_files)\n",
    "text_df['spacy_text'] = text_df['text'].apply(lambda text: nlp_preprocess(nlp, text))\n",
    "text_df.set_index('text_id', inplace=True)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4802e6",
   "metadata": {},
   "source": [
    "### 2.2. From an Excel spreadsheet\n",
    "If you have already stored your texts in an Excel spreadsheet, you can use the below code to access your spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13998266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the file path and the file name of the excel spreadsheet containing the text\n",
    "file_path = './input/'\n",
    "file_name = 'text_files.xlsx'\n",
    "\n",
    "# read the pandas dataframe containing the list of texts\n",
    "text_df = pd.read_excel(file_path + file_name)\n",
    "text_df['spacy_text'] = text_df['text'].apply(lambda text: nlp_preprocess(nlp, text))\n",
    "text_df.set_index('text_id', inplace=True)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4039347d",
   "metadata": {},
   "source": [
    "## 3. Extract the quotes\n",
    "Once your texts have been stored in a pandas dataframe, we can begin to extract the quotes from the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96151dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the column name containing the spacy text\n",
    "text_col_name = 'spacy_text'\n",
    "\n",
    "# specify whether you wish to create a parse tree for the quotes \n",
    "# you also need to specify the output file path if 'True'\n",
    "write_quote_trees_in_file = True #False\n",
    "tree_dir = './output/trees/'\n",
    "\n",
    "# create an empty list to store all detected quotes\n",
    "all_quotes = []\n",
    "\n",
    "# go through all the texts and start extracting quotes\n",
    "for row in text_df.itertuples():\n",
    "    doc_id = row.Index\n",
    "    doc = row.spacy_text\n",
    "    \n",
    "    try:        \n",
    "        # extract the quotes\n",
    "        quotes = extract_quotes(doc_id=doc_id, doc=doc, \n",
    "                                write_tree=write_quote_trees_in_file, \n",
    "                                tree_dir=tree_dir)\n",
    "        \n",
    "        # add quote_id to each quote\n",
    "        for n, quote in enumerate(quotes):\n",
    "            quote['text_id'] = doc_id\n",
    "            quote['quote_id'] = str(n)\n",
    "        \n",
    "        # store them in all_quotes\n",
    "        all_quotes.extend(quotes)\n",
    "            \n",
    "    except:\n",
    "        # this will provide some information in the case of an error\n",
    "        app_logger.exception(\"message\")\n",
    "        traceback.print_exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be6223",
   "metadata": {},
   "source": [
    "## 4. Display the quotes\n",
    "Once you are have extracted the quotes, we will store them in a pandas dataframe for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df10d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the outcome into a pandas dataframe\n",
    "quotes_df = pd.DataFrame.from_dict(all_quotes)\n",
    "\n",
    "# convert the string format quote spans in the index columns to a tuple of integers\n",
    "for column in quotes_df.columns:\n",
    "    if column.endswith('_index'):\n",
    "        quotes_df[column].replace('','(0,0)', inplace=True)\n",
    "        quotes_df[column] = quotes_df[column].apply(eval)\n",
    "\n",
    "# re-arrange the columns\n",
    "new_index = ['text_id', 'quote_id', 'quote', 'quote_index', 'speaker', 'speaker_index', \n",
    "             'verb', 'verb_index', 'quote_token_count', 'quote_type', 'is_floating_quote']\n",
    "quotes_df = quotes_df.reindex(columns=new_index)\n",
    "\n",
    "# drop unused columns\n",
    "#quotes_df.drop(['quote_token_count', 'quote_type', 'is_floating_quote', 'verb', 'verb_index'], \n",
    "#               axis=1, inplace=True)\n",
    "       \n",
    "# preview the quotes dataframe\n",
    "quotes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feec27ad",
   "metadata": {},
   "source": [
    "In general, the quotes are extracted either based on syntactic rules or heuristic (custom) rules. Some quotes can be stand-alone in a sentence, or followed by another quote (floating quote) in the same sentence.   \n",
    "**Note:** *Q (Quotation mark), S (Speaker), V (Verb), C (Content)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24dd48",
   "metadata": {},
   "source": [
    "We can show a preview of the quotes using spaCy's visualisation tool, displaCy. All you need to do is run the below function and specify the text_id you wish to analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "from spacy.tokens import Span\n",
    "\n",
    "# function to display the quotes and speakers in the text\n",
    "def show_quotes(text_id, save_to_html=True, out_dir='./output/'):\n",
    "    doc = text_df.loc[text_id, 'spacy_text']\n",
    "\n",
    "    # create a mapping dataframe between the character index and token index from the spacy text.\n",
    "    loc2tok_df = pd.DataFrame([(t.idx, t.i) for t in doc], columns = ['loc', 'token'])\n",
    "\n",
    "    # get the quotes and speakers indexes\n",
    "    locs = {\n",
    "        'QUOTE': quotes_df[quotes_df['text_id']==text_id]['quote_index'].tolist(),\n",
    "        'SPEAKER': set(quotes_df[quotes_df['text_id']==text_id]['speaker_index'].tolist())\n",
    "    }\n",
    "\n",
    "    # create displaCy code to visualise quotes and speakers \n",
    "    my_code_list = ['doc.spans[\"sc\"] = [', ']']\n",
    "    \n",
    "    for key in locs.keys():\n",
    "        for loc in locs[key]:\n",
    "            if loc!=(0,0):\n",
    "                # Find out all token indices that falls within the given span (variable loc)\n",
    "                selTokens = loc2tok_df.loc[(loc[0]<=loc2tok_df['loc']) & (loc2tok_df['loc']<loc[1]), 'token'].tolist()\n",
    "                start_token, end_token = selTokens[0], selTokens[-1] # First and last token index\n",
    "                #start_token = tokens[min(tokens.keys(), key=lambda x:abs(x-loc[0]))]\n",
    "                #end_token = tokens[min(tokens.keys(), key=lambda x:abs(x-loc[1]))]\n",
    "                span_code = \"Span(doc, {}, {}, '{}'),\".format(start_token, end_token+1, key) \n",
    "                my_code_list.insert(1,span_code)\n",
    "                \n",
    "    my_code = ''.join(my_code_list)\n",
    "\n",
    "    # formatting options\n",
    "    colors = {'QUOTE': '#7aecec', 'SPEAKER': '#bfeeb7'}\n",
    "    options = {'ents': ['QUOTE', 'SPEAKER'], \n",
    "               'colors': colors, 'top_offset': 31}\n",
    "\n",
    "    # execute the code\n",
    "    exec(my_code)\n",
    "\n",
    "    # option to save the preview as an html document\n",
    "    if save_to_html:\n",
    "        html = displacy.render(doc, style='span', options=options, jupyter=False, page=True)\n",
    "        \n",
    "        # save the quote preview into an html file\n",
    "        file = open(out_dir+text_id+'.html', 'w')\n",
    "        file.write(html)\n",
    "        file.close()\n",
    "    \n",
    "    # display the preview in this notebook\n",
    "    displacy.render(doc, style='span', options=options, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e238e391",
   "metadata": {},
   "source": [
    "By default, this function will also save the quote preview in an html file (with the text_id as the file name) inside the output directory. You can turn this option off by setting the *'save_to_html'* parameter to **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f815845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify the text_id for quote display\n",
    "text_id = 'text1'\n",
    "\n",
    "# display the quotes and the speakers in the text\n",
    "show_quotes(text_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3607fd4b",
   "metadata": {},
   "source": [
    "## 5. Save your quotes\n",
    "Finally, you can save the quote pandas dataframe into an Excel spreadsheet and download them on your local computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save quotes_df into an Excel spreadsheet\n",
    "quotes_df.to_excel('./output/quotes.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29619d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('atap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "50e9832c473c86713864f61257029e15f281e1af6f46dd8361ab2dc7ec7915dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
