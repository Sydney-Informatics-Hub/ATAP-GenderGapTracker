{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c2662a3",
   "metadata": {},
   "source": [
    "# Quote Extractor\n",
    "In this notebook, we will use the *Quote Extractor* tool to extract quotes from a list of texts. In addition to extracting the quotes, the tool provides information about who the speaker is, the location of the quote (and the speaker) in the text.  \n",
    "\n",
    "**Note:** This code has been adapted from the [GenderGapTracker](https://github.com/sfu-discourse-lab/GenderGapTracker/tree/master/NLP/main) GitHub page and modified to run on a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99ca86",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Before we begin, we need to import the necessary tools and packages for our tool to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189dd6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sjuf9909/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import codecs\n",
    "import logging\n",
    "import traceback\n",
    "from collections import Counter\n",
    "\n",
    "# matplotlib: visualization tool\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# pandas: tools for data processing\n",
    "import pandas as pd\n",
    "\n",
    "# ipywidgets: tools for interactive browser controls in Jupyter notebooks\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Layout\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "# spaCy and NLTK: natural language processing tools for working with language/text data\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import Tree\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# import the quote extractor tool\n",
    "from quote_extractor import extract_quotes, get_rawtext_files\n",
    "from config import config\n",
    "import utils\n",
    "\n",
    "# initiate the app_logger\n",
    "app_logger = utils.create_logger('quote_extractor', log_dir='logs', logger_level=logging.INFO, \n",
    "                                 file_log_level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3acbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spaCy language model...\n",
      "Finished loading.\n"
     ]
    }
   ],
   "source": [
    "# download spaCy's en_core_web_lg, the pre-trained English language tool from spaCy\n",
    "print('Loading spaCy language model...')\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "print('Finished loading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf517c9",
   "metadata": {},
   "source": [
    "## 2. Load the data\n",
    "This notebook will allow you to extract quotes directly from a text file (or a number of text files). Alternatively, you can also extract quotes from a text column inside your excel spreadsheet, if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfba236e",
   "metadata": {},
   "source": [
    "### 2.1. From a text file\n",
    "In order to extract quotes directly from a text file, please upload all your text files (.txt) below. Using the below code, we will access those files and extract the text into a pandas dataframe (in table format) for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6762ea34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded!\n"
     ]
    }
   ],
   "source": [
    "# widget to upload .txt files\n",
    "print('Upload your .txt files here:')\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='.txt', # accepted file extension \n",
    "    multiple=True  # True to accept multiple files\n",
    ")\n",
    "display(uploader)\n",
    "\n",
    "# give notification when file is uploaded\n",
    "def _cb(change):\n",
    "    clear_output()\n",
    "    print('File uploaded!')\n",
    "    \n",
    "uploader.observe(_cb, names='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "751bf2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pre-process text\n",
    "def nlp_preprocess(nlp, text):\n",
    "    # pre-process the text\n",
    "    text = sent_tokenize(text)\n",
    "    text = ' '.join(text)\n",
    "    text = utils.preprocess_text(text)\n",
    "    \n",
    "    # apply the spaCy's tool to the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fe56884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spacy_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text1</th>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "      <td>(Facebook, and, Instagram, ,, which, Facebook,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text2</th>\n",
       "      <td>(CBC News)\\nRepublican lawmakers and previous ...</td>\n",
       "      <td>((, CBC, News, ), ., \\n , Republican, lawmaker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text3</th>\n",
       "      <td>Federated States of Micronesia President David...</td>\n",
       "      <td>(Federated, States, of, Micronesia, President,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text4</th>\n",
       "      <td>Chinese state media has launched its strongest...</td>\n",
       "      <td>(Chinese, state, media, has, launched, its, st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "text_id                                                      \n",
       "text1    Facebook and Instagram, which Facebook owns, f...   \n",
       "text2    (CBC News)\\nRepublican lawmakers and previous ...   \n",
       "text3    Federated States of Micronesia President David...   \n",
       "text4    Chinese state media has launched its strongest...   \n",
       "\n",
       "                                                spacy_text  \n",
       "text_id                                                     \n",
       "text1    (Facebook, and, Instagram, ,, which, Facebook,...  \n",
       "text2    ((, CBC, News, ), ., \\n , Republican, lawmaker...  \n",
       "text3    (Federated, States, of, Micronesia, President,...  \n",
       "text4    (Chinese, state, media, has, launched, its, st...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty list for a placeholder to store all the texts\n",
    "all_files = []\n",
    "\n",
    "# search for text files (.txt) inside the folder and extract all the texts\n",
    "for input_file in uploader.value.keys():\n",
    "    text_dict = {}\n",
    "    \n",
    "    # use the text file name as the doc_id\n",
    "    doc_id = input_file.replace('.txt', '')\n",
    "    \n",
    "    try:\n",
    "        # read the text file\n",
    "        doc_lines = codecs.decode(uploader.value[input_file]['content'], encoding='utf-8')\n",
    "        \n",
    "        # store them inside a dictionary\n",
    "        text_dict['text_id'] = doc_id\n",
    "        text_dict['text'] = doc_lines\n",
    "        all_files.append(text_dict)\n",
    "            \n",
    "    except:\n",
    "        # this will provide some information in the case of an error\n",
    "        app_logger.exception(\"message\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "# convert the extracted texts into a pandas dataframe for further processing\n",
    "text_df = pd.DataFrame.from_dict(all_files)\n",
    "text_df['spacy_text'] = text_df['text'].apply(lambda text: nlp_preprocess(nlp, text))\n",
    "text_df.set_index('text_id', inplace=True)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4802e6",
   "metadata": {},
   "source": [
    "### 2.2. From an Excel spreadsheet\n",
    "If you have already stored your texts in an Excel spreadsheet, you can use the below code to access your spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03c2dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded!\n"
     ]
    }
   ],
   "source": [
    "# widget to upload .xlsx file\n",
    "print('Upload your excel spreadsheet here:')\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='.xlsx', # accepted file extension\n",
    "    multiple=False  # to accept one Excel file only\n",
    ")\n",
    "display(uploader)\n",
    "\n",
    "# give notification when file is uploaded\n",
    "uploader.observe(_cb, names='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13998266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spacy_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text1</th>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "      <td>(Facebook, and, Instagram, ,, which, Facebook,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text2</th>\n",
       "      <td>(CBC News)\\nRepublican lawmakers and previous ...</td>\n",
       "      <td>((, CBC, News, ), ., \\n , Republican, lawmaker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text3</th>\n",
       "      <td>Federated States of Micronesia President David...</td>\n",
       "      <td>(Federated, States, of, Micronesia, President,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text4</th>\n",
       "      <td>Chinese state media has launched its strongest...</td>\n",
       "      <td>(Chinese, state, media, has, launched, its, st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "text_id                                                      \n",
       "text1    Facebook and Instagram, which Facebook owns, f...   \n",
       "text2    (CBC News)\\nRepublican lawmakers and previous ...   \n",
       "text3    Federated States of Micronesia President David...   \n",
       "text4    Chinese state media has launched its strongest...   \n",
       "\n",
       "                                                spacy_text  \n",
       "text_id                                                     \n",
       "text1    (Facebook, and, Instagram, ,, which, Facebook,...  \n",
       "text2    ((, CBC, News, ), ., \\n , Republican, lawmaker...  \n",
       "text3    (Federated, States, of, Micronesia, President,...  \n",
       "text4    (Chinese, state, media, has, launched, its, st...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the pandas dataframe containing the list of texts\n",
    "text_df = pd.read_excel(io.BytesIO(uploader.data[0]))\n",
    "text_df['spacy_text'] = text_df['text'].apply(lambda text: nlp_preprocess(nlp, text))\n",
    "text_df.set_index('text_id', inplace=True)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4039347d",
   "metadata": {},
   "source": [
    "## 3. Extract the quotes\n",
    "Once your texts have been stored in a pandas dataframe, we can begin to extract the quotes from the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96151dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the column name containing the spacy text\n",
    "text_col_name = 'spacy_text'\n",
    "\n",
    "# specify whether you wish to create a parse tree for the quotes \n",
    "write_quote_trees_in_file = False \n",
    "\n",
    "# create an output folder and specify the file path if 'True'\n",
    "os.makedirs('output', exist_ok=True)\n",
    "os.makedirs('output/trees', exist_ok=True)\n",
    "tree_dir = './output/trees/'\n",
    "\n",
    "# create an empty list to store all detected quotes\n",
    "all_quotes = []\n",
    "inc_ent = ['ORG','PERSON','GPE','NORP','FAC','LOC']\n",
    "\n",
    "# go through all the texts and start extracting quotes\n",
    "for row in text_df.itertuples():\n",
    "    doc_id = row.Index\n",
    "    doc = row.spacy_text\n",
    "    \n",
    "    try:        \n",
    "        # extract the quotes\n",
    "        quotes = extract_quotes(doc_id=doc_id, doc=doc, \n",
    "                                write_tree=write_quote_trees_in_file, \n",
    "                                tree_dir=tree_dir)\n",
    "        \n",
    "        speaks, qts = [quote['speaker'] for quote in quotes], [quote['quote'] for quote in quotes]        \n",
    "        speak_ents = [[(str(ent), ent.label_) for ent in doc.ents if (str(ent) in speak) & (ent.label_ in inc_ent)] for speak in speaks]        \n",
    "        quote_ents = [[(str(ent), ent.label_) for ent in doc.ents if (str(ent) in qt) & (ent.label_ in inc_ent)] for qt in qts]\n",
    "\n",
    "        # add quote_id and named entities to each quote\n",
    "        for n, quote in enumerate(quotes):\n",
    "            quote['text_id'] = doc_id\n",
    "            quote['quote_id'] = str(n)\n",
    "            quote['speaker_entities'] = list(set(speak_ents[n]))\n",
    "            quote['quote_entities'] = list(set(quote_ents[n]))\n",
    "            \n",
    "        # store them in all_quotes\n",
    "        all_quotes.extend(quotes)\n",
    "            \n",
    "    except:\n",
    "        # this will provide some information in the case of an error\n",
    "        app_logger.exception(\"message\")\n",
    "        traceback.print_exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be6223",
   "metadata": {},
   "source": [
    "## 4. Display the quotes\n",
    "Once you are have extracted the quotes, we will store them in a pandas dataframe for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df10d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>quote_id</th>\n",
       "      <th>quote</th>\n",
       "      <th>quote_index</th>\n",
       "      <th>quote_entities</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_index</th>\n",
       "      <th>speaker_entities</th>\n",
       "      <th>verb</th>\n",
       "      <th>verb_index</th>\n",
       "      <th>quote_token_count</th>\n",
       "      <th>quote_type</th>\n",
       "      <th>is_floating_quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text1</td>\n",
       "      <td>0</td>\n",
       "      <td>\"We didn't just see a breach at the Capitol. S...</td>\n",
       "      <td>(1052, 1238)</td>\n",
       "      <td>[(Capitol, FAC), (Capitol, ORG), (the United S...</td>\n",
       "      <td>Grygiel</td>\n",
       "      <td>(1239, 1246)</td>\n",
       "      <td>[(Grygiel, PERSON)]</td>\n",
       "      <td>said</td>\n",
       "      <td>(1247, 1251)</td>\n",
       "      <td>38</td>\n",
       "      <td>Heuristic</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text1</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Social media is complicit in this because he ...</td>\n",
       "      <td>(1492, 1691)</td>\n",
       "      <td>[(the United States, GPE)]</td>\n",
       "      <td></td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>[]</td>\n",
       "      <td>caused</td>\n",
       "      <td>(1705, 1711)</td>\n",
       "      <td>39</td>\n",
       "      <td>Heuristic</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text1</td>\n",
       "      <td>2</td>\n",
       "      <td>that Trump wouldn't be able to post for 24 hou...</td>\n",
       "      <td>(84, 173)</td>\n",
       "      <td>[(Trump, PERSON), (Trump, ORG)]</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns,</td>\n",
       "      <td>(0, 44)</td>\n",
       "      <td>[(Instagram, ORG), (Facebook, ORG)]</td>\n",
       "      <td>announcing</td>\n",
       "      <td>(73, 83)</td>\n",
       "      <td>17</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text1</td>\n",
       "      <td>3</td>\n",
       "      <td>that these actions follow years of hemming and...</td>\n",
       "      <td>(302, 489)</td>\n",
       "      <td>[(Trump, PERSON), (Trump, ORG)]</td>\n",
       "      <td>experts</td>\n",
       "      <td>(288, 295)</td>\n",
       "      <td>[]</td>\n",
       "      <td>noted</td>\n",
       "      <td>(296, 301)</td>\n",
       "      <td>26</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text1</td>\n",
       "      <td>4</td>\n",
       "      <td>what happened in Washington, D.C., on Wednesda...</td>\n",
       "      <td>(592, 813)</td>\n",
       "      <td>[(D.C., GPE), (Trump, PERSON), (Trump, ORG), (...</td>\n",
       "      <td>Jennifer Grygiel, a Syracuse University commun...</td>\n",
       "      <td>(491, 586)</td>\n",
       "      <td>[(Syracuse University, ORG), (Jennifer Grygiel...</td>\n",
       "      <td>said</td>\n",
       "      <td>(587, 591)</td>\n",
       "      <td>38</td>\n",
       "      <td>S V C</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_id quote_id                                              quote  \\\n",
       "0   text1        0  \"We didn't just see a breach at the Capitol. S...   \n",
       "1   text1        1  \"Social media is complicit in this because he ...   \n",
       "2   text1        2  that Trump wouldn't be able to post for 24 hou...   \n",
       "3   text1        3  that these actions follow years of hemming and...   \n",
       "4   text1        4  what happened in Washington, D.C., on Wednesda...   \n",
       "\n",
       "    quote_index                                     quote_entities  \\\n",
       "0  (1052, 1238)  [(Capitol, FAC), (Capitol, ORG), (the United S...   \n",
       "1  (1492, 1691)                         [(the United States, GPE)]   \n",
       "2     (84, 173)                    [(Trump, PERSON), (Trump, ORG)]   \n",
       "3    (302, 489)                    [(Trump, PERSON), (Trump, ORG)]   \n",
       "4    (592, 813)  [(D.C., GPE), (Trump, PERSON), (Trump, ORG), (...   \n",
       "\n",
       "                                             speaker speaker_index  \\\n",
       "0                                            Grygiel  (1239, 1246)   \n",
       "1                                                           (0, 0)   \n",
       "2       Facebook and Instagram, which Facebook owns,       (0, 44)   \n",
       "3                                            experts    (288, 295)   \n",
       "4  Jennifer Grygiel, a Syracuse University commun...    (491, 586)   \n",
       "\n",
       "                                    speaker_entities        verb  \\\n",
       "0                                [(Grygiel, PERSON)]        said   \n",
       "1                                                 []      caused   \n",
       "2                [(Instagram, ORG), (Facebook, ORG)]  announcing   \n",
       "3                                                 []       noted   \n",
       "4  [(Syracuse University, ORG), (Jennifer Grygiel...        said   \n",
       "\n",
       "     verb_index  quote_token_count quote_type  is_floating_quote  \n",
       "0  (1247, 1251)                 38  Heuristic              False  \n",
       "1  (1705, 1711)                 39  Heuristic              False  \n",
       "2      (73, 83)                 17      S V C              False  \n",
       "3    (296, 301)                 26      S V C              False  \n",
       "4    (587, 591)                 38      S V C              False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the outcome into a pandas dataframe\n",
    "quotes_df = pd.DataFrame.from_dict(all_quotes)\n",
    "\n",
    "# convert the string format quote spans in the index columns to a tuple of integers\n",
    "for column in quotes_df.columns:\n",
    "    if column.endswith('_index'):\n",
    "        quotes_df[column].replace('','(0,0)', inplace=True)\n",
    "        quotes_df[column] = quotes_df[column].apply(eval)\n",
    "\n",
    "# re-arrange the columns\n",
    "new_index = ['text_id', 'quote_id', 'quote', 'quote_index', 'quote_entities', \n",
    "             'speaker', 'speaker_index', 'speaker_entities',\n",
    "             'verb', 'verb_index', 'quote_token_count', 'quote_type', 'is_floating_quote']\n",
    "quotes_df = quotes_df.reindex(columns=new_index)\n",
    "      \n",
    "# preview the quotes dataframe\n",
    "quotes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feec27ad",
   "metadata": {},
   "source": [
    "In general, the quotes are extracted either based on syntactic rules or heuristic (custom) rules. Some quotes can be stand-alone in a sentence, or followed by another quote (floating quote) in the same sentence.   \n",
    "\n",
    "**Quotation symbols:** *Q (Quotation mark), S (Speaker), V (Verb), C (Content)*  \n",
    "\n",
    "**Named Entities:**  *PERSON (People, including fictional), NORP (Nationalities or religious or political groups), FAC (Buildings, airports, highways, bridges, etc.), ORG (Companies, agencies, institutions, etc.), GPE (Countries, cities, states), LOC (Non-GPE locations, mountain ranges, bodies of water)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24dd48",
   "metadata": {},
   "source": [
    "We can show a preview of the quotes using spaCy's visualisation tool, displaCy. All you need to do is run the below function and specify the text_id you wish to analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0087dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "from spacy.tokens import Span\n",
    "\n",
    "# function to display the quotes and speakers in the text\n",
    "def show_quotes(text_id, show_what, save_to_html=False, out_dir='./output/'):\n",
    "    doc = text_df.loc[text_id, 'spacy_text']\n",
    "    entities = quotes_df['quote_entities']\n",
    "    \n",
    "    # create a mapping dataframe between the character index and token index from the spacy text.\n",
    "    loc2tok_df = pd.DataFrame([(t.idx, t.i) for t in doc], columns = ['loc', 'token'])\n",
    "\n",
    "    # get the quotes and speakers indexes\n",
    "    locs = {\n",
    "        'QUOTE': quotes_df[quotes_df['text_id']==text_id]['quote_index'].tolist(),\n",
    "        'SPEAKER': set(quotes_df[quotes_df['text_id']==text_id]['speaker_index'].tolist())\n",
    "    }\n",
    "\n",
    "    # create displaCy code to visualise quotes and speakers\n",
    "    my_code_list = ['doc.spans[\"sc\"] = [', ']']\n",
    "    \n",
    "    for key in locs.keys():\n",
    "        for loc in locs[key]:\n",
    "            if loc!=(0,0):\n",
    "                # Find out all token indices that falls within the given span (variable loc)\n",
    "                selTokens = loc2tok_df.loc[(loc[0]<=loc2tok_df['loc']) & (loc2tok_df['loc']<loc[1]), 'token'].tolist()\n",
    "                if 'NAMED ENTITIES' in show_what:\n",
    "                    for ent in doc.ents:\n",
    "                        if (ent.start in selTokens) & (ent.label_ in inc_ent):\n",
    "                            span_code = \"Span(doc, {}, {}, '{}'),\".format(ent.start, \n",
    "                                                              ent.end, \n",
    "                                                              ent.label_) \n",
    "                            my_code_list.insert(1,span_code)\n",
    "                if key in show_what:\n",
    "                    start_token, end_token = selTokens[0], selTokens[-1] \n",
    "                    span_code = \"Span(doc, {}, {}, '{}'),\".format(start_token, end_token+1, key) \n",
    "                    my_code_list.insert(1,span_code)\n",
    "                \n",
    "    my_code = ''.join(my_code_list)\n",
    "\n",
    "    # formatting options\n",
    "    TPL_SPAN = '''\n",
    "    <span style=\"font-weight: bold; display: inline-block; position: relative; \n",
    "    line-height: 55px\">\n",
    "        {text}\n",
    "        {span_slices}\n",
    "        {span_starts}\n",
    "    </span>\n",
    "    '''\n",
    "    \n",
    "    TPL_SPAN_SLICE = '''\n",
    "    <span style=\"background: {bg}; top: {top_offset}px; height: 4px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
    "    </span>\n",
    "    '''\n",
    "    \n",
    "    TPL_SPAN_START = '''\n",
    "    <span style=\"background: {bg}; top: {top_offset}px; height: 4px; border-top-left-radius: 3px; border-bottom-left-radius: 3px; left: -1px; width: calc(100% + 2px); position: absolute;\">\n",
    "        <span style=\"background: {bg}; z-index: 10; color: #000; top: -0.5em; padding: 2px 3px; position: absolute; font-size: 0.6em; font-weight: bold; line-height: 1; border-radius: 3px\">\n",
    "            {label}{kb_link}\n",
    "        </span>\n",
    "    </span>\n",
    "    '''\n",
    "    \n",
    "    colors = {'QUOTE': '#66ccff', 'SPEAKER': '#66ff99'}\n",
    "    options = {'ents': ['QUOTE', 'SPEAKER'], \n",
    "               'colors': colors, \n",
    "               'top_offset': 42,\n",
    "               'template': {'span':TPL_SPAN,\n",
    "                           'slice':TPL_SPAN_SLICE,\n",
    "                           'start':TPL_SPAN_START},\n",
    "               'span_label_offset': 14,\n",
    "               'top_offset_step':14}\n",
    "\n",
    "    # execute the code\n",
    "    exec(my_code)\n",
    "\n",
    "    # option to save the preview as an html document\n",
    "    if save_to_html:\n",
    "        html = displacy.render(doc, style='span', options=options, jupyter=False, page=True)\n",
    "        \n",
    "        # save the quote preview into an html file\n",
    "        file = open(out_dir+text_id+'.html', 'w')\n",
    "        file.write(html)\n",
    "        file.close()\n",
    "    \n",
    "    # display the preview in this notebook\n",
    "    displacy.render(doc, style='span', options=options, jupyter=True)\n",
    "    \n",
    "# function to display top entities\n",
    "def common_ent(text_id, which_ent='speaker_entities',top_n=5):\n",
    "    # get the most common entities\n",
    "    most_ent = quotes_df[quotes_df['text_id']==text_id][which_ent].tolist()\n",
    "    most_ent = list(filter(None,most_ent))\n",
    "    most_ent = [ent for most in most_ent for ent in most]\n",
    "    most_ent = Counter([ent_name for ent_name, ent_label in most_ent])\n",
    "    top_ent = dict(most_ent.most_common()[:top_n])\n",
    "    \n",
    "    # visualize\n",
    "    plt.rcParams[\"figure.figsize\"] = [10, 3]\n",
    "    plt.bar(top_ent.keys(), top_ent.values())\n",
    "    plt.title('Top {} {} in {}'.format(min(top_n,len(top_ent.keys())),which_ent,text_id))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e238e391",
   "metadata": {},
   "source": [
    "By default, this function will also save the quote preview in an html file (with the text_id as the file name) inside the output directory. You can turn this option off by setting the *'save_to_html'* parameter to **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d7b3fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97cf07d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d927d48f9a844d4a24cd7d8c17cca0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='text3', description='Enter Text ID:'), SelectMultiple(description='Show:', index=(0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widget for entering text_id\n",
    "text = widgets.Text(\n",
    "    value='text3',\n",
    "    description='Enter Text ID:',\n",
    "    style=dict(font_style='italic', fontweight='bold'))\n",
    "\n",
    "# widget to select what to preview, i.e., speaker, quote, named entities\n",
    "menu = widgets.SelectMultiple(\n",
    "    options=['SPEAKER', 'QUOTE', 'NAMED ENTITIES'],\n",
    "    value=['SPEAKER', 'QUOTE', 'NAMED ENTITIES'],\n",
    "    rows=3,\n",
    "    description='Show:',\n",
    "    disabled=False,\n",
    "    layout=Layout(margin='10px 0px 10px 2px')\n",
    ")\n",
    "\n",
    "# widget to show the preview\n",
    "preview_button = widgets.Button(description='Click to preview', \n",
    "                                layout=Layout(margin='5px 0px 10px 120px'),\n",
    "                                style=dict(font_style='italic',\n",
    "                                           font_weight='bold'))\n",
    "preview_out = widgets.Output()\n",
    "\n",
    "def on_preview_button_clicked(_):\n",
    "    with preview_out:\n",
    "        # what happens when we click the preview_button\n",
    "        clear_output()\n",
    "        text_id = text.value\n",
    "        show_what = menu.value\n",
    "        try:\n",
    "            show_quotes(text_id, show_what)\n",
    "        except:\n",
    "            print('The text_id you entered does not exist. Please enter the correct text_id.')\n",
    "\n",
    "# link the preview_button with the function\n",
    "preview_button.on_click(on_preview_button_clicked)\n",
    "\n",
    "# widget to save the preview\n",
    "save_button = widgets.Button(description='Save preview', \n",
    "                             layout=Layout(margin='5px 0px 10px 120px'),\n",
    "                             style=dict(font_style='italic',\n",
    "                                        font_weight='bold'))\n",
    "\n",
    "def on_save_button_clicked(_):\n",
    "    with preview_out:\n",
    "        # what happens when we click the save_button\n",
    "        clear_output()\n",
    "        text_id = text.value\n",
    "        show_what = menu.value\n",
    "        try:\n",
    "            show_quotes(text_id, show_what, save_to_html=True)\n",
    "            print('Preview saved!')\n",
    "        except:\n",
    "            print('The text_id you entered does not exist. Please enter the correct text_id.')\n",
    "\n",
    "# link the save_button with the function\n",
    "save_button.on_click(on_save_button_clicked)\n",
    "\n",
    "# widget to show top 5 entities\n",
    "top_button = widgets.Button(description='Top 5 entities', \n",
    "                             layout=Layout(margin='5px 0px 10px 120px'),\n",
    "                             style=dict(font_style='italic',\n",
    "                                        font_weight='bold'))\n",
    "top_out = widgets.Output()\n",
    "\n",
    "def on_top_button_clicked(_):\n",
    "    with top_out:\n",
    "        # what happens when we click the top_button\n",
    "        clear_output()\n",
    "        text_id = text.value\n",
    "        try:\n",
    "            common_ent(text_id, which_ent='speaker_entities',top_n=5)\n",
    "            common_ent(text_id, which_ent='quote_entities',top_n=5)\n",
    "        except:\n",
    "            print('The text_id you entered does not exist. Please enter the correct text_id.')\n",
    "\n",
    "# link the top_button with the function\n",
    "top_button.on_click(on_top_button_clicked)\n",
    "\n",
    "# displaying buttons and their outputs\n",
    "box = widgets.VBox([text, menu, \n",
    "                    preview_button, save_button, top_button, \n",
    "                    top_out, preview_out])\n",
    "box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3607fd4b",
   "metadata": {},
   "source": [
    "## 5. Save your quotes\n",
    "Finally, you can save the quote pandas dataframe into an Excel spreadsheet and download them on your local computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec7d0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save quotes_df into an Excel spreadsheet\n",
    "quotes_df.to_excel('./output/quotes.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3f6c918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /opt/anaconda3/envs/quote_display:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "alabaster                 0.7.12             pyhd3eb1b0_0  \r\n",
      "appdirs                   1.4.4              pyhd3eb1b0_0  \r\n",
      "applaunchservices         0.2.1              pyhd3eb1b0_0  \r\n",
      "appnope                   0.1.2           py38hecd8cb5_1001  \r\n",
      "argon2-cffi               21.3.0             pyhd3eb1b0_0  \r\n",
      "argon2-cffi-bindings      21.2.0           py38hca72f7f_0  \r\n",
      "arrow                     1.2.2              pyhd3eb1b0_0  \r\n",
      "astroid                   2.9.0            py38hecd8cb5_0  \r\n",
      "asttokens                 2.0.5              pyhd3eb1b0_0  \r\n",
      "atomicwrites              1.4.0                      py_0  \r\n",
      "attrs                     21.4.0             pyhd3eb1b0_0  \r\n",
      "autopep8                  1.5.6              pyhd3eb1b0_0  \r\n",
      "babel                     2.9.1              pyhd3eb1b0_0  \r\n",
      "backcall                  0.2.0              pyhd3eb1b0_0  \r\n",
      "beautifulsoup4            4.11.1           py38hecd8cb5_0  \r\n",
      "binaryornot               0.4.4              pyhd3eb1b0_1  \r\n",
      "black                     19.10b0                    py_0  \r\n",
      "blas                      1.0                         mkl  \r\n",
      "bleach                    4.1.0              pyhd3eb1b0_0  \r\n",
      "blis                      0.7.8                    pypi_0    pypi\r\n",
      "boto3                     1.24.18                  pypi_0    pypi\r\n",
      "botocore                  1.27.18                  pypi_0    pypi\r\n",
      "brotli                    1.0.9                hb1e8313_2  \r\n",
      "brotlipy                  0.7.0           py38h9ed2024_1003  \r\n",
      "ca-certificates           2022.4.26            hecd8cb5_0  \r\n",
      "catalogue                 2.0.7                    pypi_0    pypi\r\n",
      "certifi                   2022.6.15        py38hecd8cb5_0  \r\n",
      "cffi                      1.15.0           py38hc55c11b_1  \r\n",
      "chardet                   5.0.0                    pypi_0    pypi\r\n",
      "charset-normalizer        2.0.12                   pypi_0    pypi\r\n",
      "click                     8.1.3                    pypi_0    pypi\r\n",
      "cloudpickle               2.0.0              pyhd3eb1b0_0  \r\n",
      "colorama                  0.4.4              pyhd3eb1b0_0  \r\n",
      "cookiecutter              1.7.3              pyhd3eb1b0_0  \r\n",
      "cryptography              37.0.1           py38hf6deb26_0  \r\n",
      "cycler                    0.11.0             pyhd3eb1b0_0  \r\n",
      "cymem                     2.0.6                    pypi_0    pypi\r\n",
      "dbus                      1.13.18              h18a8e69_0  \r\n",
      "debugpy                   1.5.1            py38he9d5cce_0  \r\n",
      "decorator                 5.1.1              pyhd3eb1b0_0  \r\n",
      "defusedxml                0.7.1              pyhd3eb1b0_0  \r\n",
      "diff-match-patch          20200713           pyhd3eb1b0_0  \r\n",
      "docutils                  0.18.1                   pypi_0    pypi\r\n",
      "en-core-web-lg            3.3.0                    pypi_0    pypi\r\n",
      "entrypoints               0.4              py38hecd8cb5_0  \r\n",
      "et_xmlfile                1.1.0            py38hecd8cb5_0  \r\n",
      "executing                 0.8.3              pyhd3eb1b0_0  \r\n",
      "expat                     2.4.4                he9d5cce_0  \r\n",
      "flake8                    3.9.0              pyhd3eb1b0_0  \r\n",
      "flask                     2.1.2                    pypi_0    pypi\r\n",
      "fonttools                 4.25.0             pyhd3eb1b0_0  \r\n",
      "freetype                  2.11.0               hd8bbffd_0  \r\n",
      "future                    0.18.2                   py38_1  \r\n",
      "gettext                   0.21.0               h7535e17_0  \r\n",
      "giflib                    5.2.1                haf1e3a3_0  \r\n",
      "glib                      2.69.1               h8346a28_1  \r\n",
      "gunicorn                  20.1.0                   pypi_0    pypi\r\n",
      "icu                       58.2                 h0a44026_3  \r\n",
      "idna                      3.3                pyhd3eb1b0_0  \r\n",
      "imagesize                 1.3.0              pyhd3eb1b0_0  \r\n",
      "importlib-metadata        4.12.0                   pypi_0    pypi\r\n",
      "importlib-resources       5.8.0                    pypi_0    pypi\r\n",
      "importlib_metadata        4.11.3               hd3eb1b0_0  \r\n",
      "importlib_resources       5.2.0              pyhd3eb1b0_1  \r\n",
      "inflection                0.5.1            py38hecd8cb5_0  \r\n",
      "intel-openmp              2021.4.0          hecd8cb5_3538  \r\n",
      "intervaltree              3.1.0              pyhd3eb1b0_0  \r\n",
      "ipykernel                 6.9.1            py38hecd8cb5_0  \r\n",
      "ipython                   8.3.0            py38hecd8cb5_0  \r\n",
      "ipython_genutils          0.2.0              pyhd3eb1b0_1  \r\n",
      "ipywidgets                7.6.5              pyhd3eb1b0_1  \r\n",
      "isort                     5.9.3              pyhd3eb1b0_0  \r\n",
      "itsdangerous              2.1.2                    pypi_0    pypi\r\n",
      "jedi                      0.17.2           py38hecd8cb5_1  \r\n",
      "jinja2                    3.1.2                    pypi_0    pypi\r\n",
      "jinja2-time               0.2.0              pyhd3eb1b0_3  \r\n",
      "jmespath                  1.0.1                    pypi_0    pypi\r\n",
      "joblib                    1.1.0                    pypi_0    pypi\r\n",
      "jpeg                      9e                   hca72f7f_0  \r\n",
      "jsonschema                4.6.0                    pypi_0    pypi\r\n",
      "jupyter_client            7.2.2            py38hecd8cb5_0  \r\n",
      "jupyter_core              4.10.0           py38hecd8cb5_0  \r\n",
      "jupyterlab_pygments       0.1.2                      py_0  \r\n",
      "jupyterlab_widgets        1.0.0              pyhd3eb1b0_1  \r\n",
      "keyring                   23.4.0           py38hecd8cb5_0  \r\n",
      "kiwisolver                1.4.2            py38he9d5cce_0  \r\n",
      "langcodes                 3.3.0                    pypi_0    pypi\r\n",
      "lazy-object-proxy         1.6.0            py38h9ed2024_0  \r\n",
      "lcms2                     2.12                 hf1fd2bf_0  \r\n",
      "libcxx                    12.0.0               h2f01273_0  \r\n",
      "libffi                    3.3                  hb1e8313_2  \r\n",
      "libiconv                  1.16                 hca72f7f_2  \r\n",
      "libpng                    1.6.37               ha441bb4_0  \r\n",
      "libsodium                 1.0.18               h1de35cc_0  \r\n",
      "libspatialindex           1.9.3                h23ab428_0  \r\n",
      "libtiff                   4.2.0                hdb42f99_1  \r\n",
      "libwebp                   1.2.2                h56c3ce4_0  \r\n",
      "libwebp-base              1.2.2                hca72f7f_0  \r\n",
      "libxml2                   2.9.14               hbf8cd5e_0  \r\n",
      "llvm-openmp               12.0.0               h0dcd299_1  \r\n",
      "lz4-c                     1.9.3                h23ab428_1  \r\n",
      "markupsafe                2.1.1            py38hca72f7f_0  \r\n",
      "matplotlib                3.5.1            py38hecd8cb5_1  \r\n",
      "matplotlib-base           3.5.1            py38hfb0c5b7_1  \r\n",
      "matplotlib-inline         0.1.2              pyhd3eb1b0_2  \r\n",
      "mccabe                    0.6.1                    py38_1  \r\n",
      "mistune                   0.8.4           py38h1de35cc_1001  \r\n",
      "mkl                       2021.4.0           hecd8cb5_637  \r\n",
      "mkl-service               2.4.0            py38h9ed2024_0  \r\n",
      "mkl_fft                   1.3.1            py38h4ab4a9b_0  \r\n",
      "mkl_random                1.2.2            py38hb2f4e1b_0  \r\n",
      "munkres                   1.1.4                      py_0  \r\n",
      "murmurhash                1.0.7                    pypi_0    pypi\r\n",
      "mypy_extensions           0.4.3            py38hecd8cb5_1  \r\n",
      "nbclient                  0.5.13           py38hecd8cb5_0  \r\n",
      "nbconvert                 6.4.4            py38hecd8cb5_0  \r\n",
      "nbformat                  5.3.0            py38hecd8cb5_0  \r\n",
      "ncurses                   6.3                  hca72f7f_2  \r\n",
      "nest-asyncio              1.5.5            py38hecd8cb5_0  \r\n",
      "neuralcoref               4.0                      pypi_0    pypi\r\n",
      "nltk                      3.7                      pypi_0    pypi\r\n",
      "notebook                  6.4.11           py38hecd8cb5_0  \r\n",
      "numpy                     1.23.0                   pypi_0    pypi\r\n",
      "numpy-base                1.22.3           py38h3b1a694_0  \r\n",
      "numpydoc                  1.2                pyhd3eb1b0_0  \r\n",
      "openpyxl                  3.0.9              pyhd3eb1b0_0  \r\n",
      "openssl                   1.1.1p               hca72f7f_0  \r\n",
      "packaging                 21.3               pyhd3eb1b0_0  \r\n",
      "pandas                    1.4.3                    pypi_0    pypi\r\n",
      "pandocfilters             1.5.0              pyhd3eb1b0_0  \r\n",
      "parso                     0.7.0                      py_0  \r\n",
      "pathspec                  0.7.0                      py_0  \r\n",
      "pathy                     0.6.1                    pypi_0    pypi\r\n",
      "pcre                      8.45                 h23ab428_0  \r\n",
      "pexpect                   4.8.0              pyhd3eb1b0_3  \r\n",
      "pickleshare               0.7.5           pyhd3eb1b0_1003  \r\n",
      "pillow                    9.0.1            py38hde71d04_0  \r\n",
      "pip                       21.2.4           py38hecd8cb5_0  \r\n",
      "plac                      1.3.5                    pypi_0    pypi\r\n",
      "platformdirs              2.4.0              pyhd3eb1b0_0  \r\n",
      "pluggy                    1.0.0            py38hecd8cb5_1  \r\n",
      "poyo                      0.5.0              pyhd3eb1b0_0  \r\n",
      "preshed                   3.0.6                    pypi_0    pypi\r\n",
      "prometheus_client         0.13.1             pyhd3eb1b0_0  \r\n",
      "prompt-toolkit            3.0.20             pyhd3eb1b0_0  \r\n",
      "psutil                    5.8.0            py38h9ed2024_1  \r\n",
      "ptyprocess                0.7.0              pyhd3eb1b0_2  \r\n",
      "pure_eval                 0.2.2              pyhd3eb1b0_0  \r\n",
      "pycodestyle               2.6.0              pyhd3eb1b0_0  \r\n",
      "pycparser                 2.21               pyhd3eb1b0_0  \r\n",
      "pydantic                  1.8.2                    pypi_0    pypi\r\n",
      "pydocstyle                6.1.1              pyhd3eb1b0_0  \r\n",
      "pyflakes                  2.2.0              pyhd3eb1b0_0  \r\n",
      "pygments                  2.11.2             pyhd3eb1b0_0  \r\n",
      "pylint                    2.12.2           py38hecd8cb5_1  \r\n",
      "pyls-black                0.4.6                hd3eb1b0_0  \r\n",
      "pyls-spyder               0.3.2              pyhd3eb1b0_0  \r\n",
      "pymongo                   4.1.1                    pypi_0    pypi\r\n",
      "pyopenssl                 22.0.0             pyhd3eb1b0_0  \r\n",
      "pyparsing                 3.0.9                    pypi_0    pypi\r\n",
      "pyqt                      5.9.2            py38h655552a_2  \r\n",
      "pyrsistent                0.18.1                   pypi_0    pypi\r\n",
      "pysocks                   1.7.1                    py38_1  \r\n",
      "python                    3.8.13               hdfd78df_0  \r\n",
      "python-dateutil           2.8.2              pyhd3eb1b0_0  \r\n",
      "python-fastjsonschema     2.15.1             pyhd3eb1b0_0  \r\n",
      "python-jsonrpc-server     0.4.0                      py_0  \r\n",
      "python-language-server    0.36.2             pyhd3eb1b0_0  \r\n",
      "python-slugify            5.0.2              pyhd3eb1b0_0  \r\n",
      "python.app                3                py38hca72f7f_0  \r\n",
      "pytz                      2022.1           py38hecd8cb5_0  \r\n",
      "pyyaml                    6.0              py38hca72f7f_1  \r\n",
      "pyzmq                     22.3.0           py38he9d5cce_2  \r\n",
      "qdarkstyle                3.0.2              pyhd3eb1b0_0  \r\n",
      "qstylizer                 0.1.10             pyhd3eb1b0_0  \r\n",
      "qt                        5.9.7                h468cd18_1  \r\n",
      "qtawesome                 1.0.3              pyhd3eb1b0_0  \r\n",
      "qtconsole                 5.3.0              pyhd3eb1b0_0  \r\n",
      "qtpy                      2.0.1              pyhd3eb1b0_0  \r\n",
      "readline                  8.1.2                hca72f7f_1  \r\n",
      "regex                     2022.6.2                 pypi_0    pypi\r\n",
      "requests                  2.28.0                   pypi_0    pypi\r\n",
      "rope                      0.22.0             pyhd3eb1b0_0  \r\n",
      "rtree                     0.9.7            py38hecd8cb5_1  \r\n",
      "s3transfer                0.6.0                    pypi_0    pypi\r\n",
      "send2trash                1.8.0              pyhd3eb1b0_1  \r\n",
      "setuptools                61.2.0           py38hecd8cb5_0  \r\n",
      "sip                       4.19.8           py38h0a44026_0  \r\n",
      "six                       1.16.0             pyhd3eb1b0_1  \r\n",
      "smart-open                5.2.1                    pypi_0    pypi\r\n",
      "snowballstemmer           2.2.0              pyhd3eb1b0_0  \r\n",
      "sortedcontainers          2.4.0              pyhd3eb1b0_0  \r\n",
      "soupsieve                 2.3.1              pyhd3eb1b0_0  \r\n",
      "spacy                     3.3.1                    pypi_0    pypi\r\n",
      "spacy-legacy              3.0.9                    pypi_0    pypi\r\n",
      "spacy-loggers             1.0.2                    pypi_0    pypi\r\n",
      "sphinx                    4.4.0              pyhd3eb1b0_0  \r\n",
      "sphinxcontrib-applehelp   1.0.2              pyhd3eb1b0_0  \r\n",
      "sphinxcontrib-devhelp     1.0.2              pyhd3eb1b0_0  \r\n",
      "sphinxcontrib-htmlhelp    2.0.0              pyhd3eb1b0_0  \r\n",
      "sphinxcontrib-jsmath      1.0.1              pyhd3eb1b0_0  \r\n",
      "sphinxcontrib-qthelp      1.0.3              pyhd3eb1b0_0  \r\n",
      "sphinxcontrib-serializinghtml 1.1.5              pyhd3eb1b0_0  \r\n",
      "spyder                    5.0.5            py38hecd8cb5_2  \r\n",
      "spyder-kernels            2.0.5            py38hecd8cb5_0  \r\n",
      "sqlite                    3.38.5               h707629a_0  \r\n",
      "srsly                     2.4.3                    pypi_0    pypi\r\n",
      "stack_data                0.2.0              pyhd3eb1b0_0  \r\n",
      "terminado                 0.13.1           py38hecd8cb5_0  \r\n",
      "testpath                  0.6.0            py38hecd8cb5_0  \r\n",
      "text-unidecode            1.3                pyhd3eb1b0_0  \r\n",
      "textdistance              4.2.1              pyhd3eb1b0_0  \r\n",
      "thinc                     8.0.17                   pypi_0    pypi\r\n",
      "three-merge               0.1.1              pyhd3eb1b0_0  \r\n",
      "tinycss                   0.4             pyhd3eb1b0_1002  \r\n",
      "tk                        8.6.12               h5d9f67b_0  \r\n",
      "toml                      0.10.2             pyhd3eb1b0_0  \r\n",
      "tornado                   6.1              py38h9ed2024_0  \r\n",
      "tqdm                      4.64.0                   pypi_0    pypi\r\n",
      "traitlets                 5.1.1              pyhd3eb1b0_0  \r\n",
      "typed-ast                 1.4.3            py38h9ed2024_1  \r\n",
      "typer                     0.4.1                    pypi_0    pypi\r\n",
      "typing-extensions         4.2.0                    pypi_0    pypi\r\n",
      "typing_extensions         4.1.1              pyh06a4308_0  \r\n",
      "ujson                     5.1.0            py38he9d5cce_0  \r\n",
      "unidecode                 1.2.0              pyhd3eb1b0_0  \r\n",
      "urllib3                   1.26.9           py38hecd8cb5_0  \r\n",
      "wasabi                    0.9.1                    pypi_0    pypi\r\n",
      "watchdog                  2.1.6            py38h999c104_0  \r\n",
      "wcwidth                   0.2.5              pyhd3eb1b0_0  \r\n",
      "webencodings              0.5.1                    py38_1  \r\n",
      "werkzeug                  2.1.2                    pypi_0    pypi\r\n",
      "wheel                     0.37.1             pyhd3eb1b0_0  \r\n",
      "widgetsnbextension        3.5.2            py38hecd8cb5_0  \r\n",
      "wrapt                     1.13.3           py38hca72f7f_2  \r\n",
      "wurlitzer                 3.0.2            py38hecd8cb5_0  \r\n",
      "xlrd                      2.0.1                    pypi_0    pypi\r\n",
      "xz                        5.2.5                hca72f7f_1  \r\n",
      "yaml                      0.2.5                haf1e3a3_0  \r\n",
      "yapf                      0.31.0             pyhd3eb1b0_0  \r\n",
      "zeromq                    4.3.4                h23ab428_0  \r\n",
      "zipp                      3.8.0            py38hecd8cb5_0  \r\n",
      "zlib                      1.2.12               h4dc903c_2  \r\n",
      "zstd                      1.5.2                hcb37349_0  \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d2924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "50e9832c473c86713864f61257029e15f281e1af6f46dd8361ab2dc7ec7915dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
