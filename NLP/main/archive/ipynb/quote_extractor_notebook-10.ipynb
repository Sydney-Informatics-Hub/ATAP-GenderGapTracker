{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c2662a3",
   "metadata": {},
   "source": [
    "# Quote Extractor\n",
    "In this notebook, we will use the *Quote Extractor* tool to extract quotes from a list of texts. In addition to extracting the quote, the tool also provides some useful information such as who the speaker is, the location of the quote (and the speaker) within the text, the length of the quote, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99ca86",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Before we begin, we need to import the necessary tools and packages for our tool to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189dd6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sjuf9909/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "# pandas: tools for data processing\n",
    "import pandas as pd\n",
    "\n",
    "# spaCy and NLTK: natural language processing tools for working with language/text data\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import Tree\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# import the quote extractor tool\n",
    "from quote_extractor import extract_quotes, get_rawtext_files\n",
    "from config import config\n",
    "import utils\n",
    "\n",
    "# initiate the app_logger\n",
    "app_logger = utils.create_logger('quote_extractor', log_dir='logs', logger_level=logging.INFO, \n",
    "                                 file_log_level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3acbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spaCy language model...\n",
      "Finished loading.\n"
     ]
    }
   ],
   "source": [
    "# download spaCy's en_core_web_lg, the pre-trained English language tool from spaCy\n",
    "print('Loading spaCy language model...')\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "print('Finished loading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf517c9",
   "metadata": {},
   "source": [
    "## 2. Load the data\n",
    "This notebook will allow you to extract quotes directly from a text file (or a number of text files). Alternatively, you can also extract quotes from a text column inside your excel spreadsheet, if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f6f8b1",
   "metadata": {},
   "source": [
    "### 2.1. From a text file\n",
    "In order to extract quotes directly from a text file, you need to store all your text files (.txt) into a folder, e.g., the 'input' folder in the below example. Using the below code, we will access those files and extract the text into a pandas dataframe (in table format) for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200494c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test2</td>\n",
       "      <td>(CBC News)\\n\\nRepublican lawmakers and previou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_id                                              texts\n",
       "0   test1  Facebook and Instagram, which Facebook owns, f...\n",
       "1   test2  (CBC News)\\n\\nRepublican lawmakers and previou..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify the file path to the folder you use to store your text files\n",
    "file_path = './input/'\n",
    "\n",
    "# create an empty list for a placeholder to store all the texts\n",
    "all_files = []\n",
    "\n",
    "# search for text files (.txt) inside the folder and extract all the texts\n",
    "for input_file in get_rawtext_files(file_path):\n",
    "    text_dict = {}\n",
    "    \n",
    "    # use the text file name as the doc_id\n",
    "    doc_id = input_file.replace('.txt', '')\n",
    "    \n",
    "    try:\n",
    "        # read the text file\n",
    "        doc_lines = open(os.path.join(file_path, input_file), 'r').readlines()\n",
    "        doc_lines = '\\n'.join(doc_lines)\n",
    "        \n",
    "        # store them inside a dictionary\n",
    "        text_dict['text_id'] = doc_id\n",
    "        text_dict['texts'] = doc_lines\n",
    "        all_files.append(text_dict)\n",
    "            \n",
    "    except:\n",
    "        # this will provide some information in the case of an error\n",
    "        app_logger.exception(\"message\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "# convert the extracted texts into a pandas dataframe for further processing\n",
    "text_df = pd.DataFrame.from_dict(all_files)\n",
    "text_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82a286",
   "metadata": {},
   "source": [
    "### 2.2. From an Excel spreadsheet\n",
    "If you have already stored your texts in an Excel spreadsheet, you can use the below code to access your spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92166ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text1</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text2</td>\n",
       "      <td>(CBC News)\\nRepublican lawmakers and previous ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_id                                              texts\n",
       "0   text1  Facebook and Instagram, which Facebook owns, f...\n",
       "1   text2  (CBC News)\\nRepublican lawmakers and previous ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter the file path and the file name of the excel spreadsheet containing the text\n",
    "file_path = './input/'\n",
    "file_name = 'text_files.xlsx'\n",
    "\n",
    "# read the pandas dataframe containing the list of texts\n",
    "text_df = pd.read_excel(file_path + file_name)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed400ec",
   "metadata": {},
   "source": [
    "## 3. Extract the quotes\n",
    "Once your texts have been extracted and stored into a pandas dataframe, we can begin to extract the quotes from the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96151dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the column name containing the text\n",
    "text_col_name = 'texts'\n",
    "\n",
    "# specify whether you wish to create a parse tree for the quotes \n",
    "# you also need to specify the output file path if 'True'\n",
    "write_quote_trees_in_file = False\n",
    "tree_dir = './output/trees/'\n",
    "\n",
    "# create an empty list to store all detected quotes\n",
    "all_quotes = []\n",
    "\n",
    "# go through all the texts and start extracting quotes\n",
    "for n, text in enumerate(text_df[text_col_name]):\n",
    "    doc_id = text_df['text_id'][n]\n",
    "    \n",
    "    try:\n",
    "        # pre-process the text\n",
    "        text = sent_tokenize(text)\n",
    "        text = \" \".join(text)\n",
    "        text = utils.preprocess_text(text)\n",
    "        \n",
    "        # apply the spaCy's tool to the text\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        # extract the quotes\n",
    "        quotes = extract_quotes(doc_id=doc_id, doc=doc, \n",
    "                                write_tree=write_quote_trees_in_file, \n",
    "                                tree_dir=tree_dir)\n",
    "        \n",
    "        # add quote_id to each quote\n",
    "        for n, quote in enumerate(quotes):\n",
    "            quote['quote_id']=doc_id + '-' + str(n+1)\n",
    "        \n",
    "        # store them in all_quotes\n",
    "        all_quotes.extend(quotes)\n",
    "            \n",
    "    except:\n",
    "        # this will provide some information in the case of an error\n",
    "        app_logger.exception(\"message\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67621ca",
   "metadata": {},
   "source": [
    "We have extracted the quotes from all texts. Now, let's generate a preview of the extracted quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a425204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote number: 0\n",
      "Speaker: Grygiel\n",
      "Speaker_Index: (1239,1246)\n",
      "Quote: \"We didn't just see a breach at the Capitol. Social media platforms have been breached by the president repeatedly. This is disinformation. This was a coup attempt in the United States.\"\n",
      "Quote_Index: (1052,1238)\n",
      "Verb: said\n",
      "Verb_Index: (1247,1251)\n",
      "Quote_Token_Count: 38\n",
      "Quote_Type: Heuristic\n",
      "Is_Floating_Quote: False\n",
      "Quote_Id: text1-1\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Quote number: 1\n",
      "Speaker: Facebook and Instagram, which Facebook owns\n",
      "Speaker_Index: (0,43)\n",
      "Quote: that Trump wouldn't be able to post for 24 hours following two violations of its policies\n",
      "Quote_Index: (84,173)\n",
      "Verb: announcing\n",
      "Verb_Index: (73,83)\n",
      "Quote_Token_Count: 17\n",
      "Quote_Type: SVC\n",
      "Is_Floating_Quote: False\n",
      "Quote_Id: text1-2\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Quote number: 2\n",
      "Speaker: experts\n",
      "Speaker_Index: (288,295)\n",
      "Quote: that these actions follow years of hemming and hawing regarding Trump and his supporters spreading dangerous misinformation and encouraging violence that contributed to Wednesday's events\n",
      "Quote_Index: (302,489)\n",
      "Verb: noted\n",
      "Verb_Index: (296,301)\n",
      "Quote_Token_Count: 26\n",
      "Quote_Type: SVC\n",
      "Is_Floating_Quote: False\n",
      "Quote_Id: text1-3\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# generate a preview of the quotes\n",
    "for n, q in enumerate(all_quotes[:min(3,len(all_quotes))]):\n",
    "    print('Quote number:',n)\n",
    "    for key, value in q.items():\n",
    "        print(key.title() + ': ' + str(value))\n",
    "    print('-' * 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dd6f27",
   "metadata": {},
   "source": [
    "## 4. Save your quotes\n",
    "Once you are happy with the extracted quotes, you can save them back into an Excel spreadsheet for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70666e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote_id</th>\n",
       "      <th>quote</th>\n",
       "      <th>quote_index</th>\n",
       "      <th>quote_token_count</th>\n",
       "      <th>quote_type</th>\n",
       "      <th>is_floating_quote</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_index</th>\n",
       "      <th>verb</th>\n",
       "      <th>verb_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text1-1</td>\n",
       "      <td>\"We didn't just see a breach at the Capitol. S...</td>\n",
       "      <td>(1052,1238)</td>\n",
       "      <td>38</td>\n",
       "      <td>Heuristic</td>\n",
       "      <td>False</td>\n",
       "      <td>Grygiel</td>\n",
       "      <td>(1239,1246)</td>\n",
       "      <td>said</td>\n",
       "      <td>(1247,1251)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text1-2</td>\n",
       "      <td>that Trump wouldn't be able to post for 24 hou...</td>\n",
       "      <td>(84,173)</td>\n",
       "      <td>17</td>\n",
       "      <td>SVC</td>\n",
       "      <td>False</td>\n",
       "      <td>Facebook and Instagram, which Facebook owns</td>\n",
       "      <td>(0,43)</td>\n",
       "      <td>announcing</td>\n",
       "      <td>(73,83)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text1-3</td>\n",
       "      <td>that these actions follow years of hemming and...</td>\n",
       "      <td>(302,489)</td>\n",
       "      <td>26</td>\n",
       "      <td>SVC</td>\n",
       "      <td>False</td>\n",
       "      <td>experts</td>\n",
       "      <td>(288,295)</td>\n",
       "      <td>noted</td>\n",
       "      <td>(296,301)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text1-4</td>\n",
       "      <td>what happened in Washington, D.C.</td>\n",
       "      <td>(592,625)</td>\n",
       "      <td>6</td>\n",
       "      <td>SVC</td>\n",
       "      <td>False</td>\n",
       "      <td>Jennifer Grygiel, a Syracuse University commun...</td>\n",
       "      <td>(491,586)</td>\n",
       "      <td>said</td>\n",
       "      <td>(587,591)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text1-5</td>\n",
       "      <td>, on Wednesday is a direct result of Trump's u...</td>\n",
       "      <td>(625,813)</td>\n",
       "      <td>32</td>\n",
       "      <td>SVC</td>\n",
       "      <td>False</td>\n",
       "      <td>Jennifer Grygiel, a Syracuse University commun...</td>\n",
       "      <td>(491,586)</td>\n",
       "      <td>said</td>\n",
       "      <td>(587,591)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  quote_id                                              quote  quote_index  \\\n",
       "0  text1-1  \"We didn't just see a breach at the Capitol. S...  (1052,1238)   \n",
       "1  text1-2  that Trump wouldn't be able to post for 24 hou...     (84,173)   \n",
       "2  text1-3  that these actions follow years of hemming and...    (302,489)   \n",
       "3  text1-4                  what happened in Washington, D.C.    (592,625)   \n",
       "4  text1-5  , on Wednesday is a direct result of Trump's u...    (625,813)   \n",
       "\n",
       "   quote_token_count quote_type  is_floating_quote  \\\n",
       "0                 38  Heuristic              False   \n",
       "1                 17        SVC              False   \n",
       "2                 26        SVC              False   \n",
       "3                  6        SVC              False   \n",
       "4                 32        SVC              False   \n",
       "\n",
       "                                             speaker speaker_index  \\\n",
       "0                                            Grygiel   (1239,1246)   \n",
       "1        Facebook and Instagram, which Facebook owns        (0,43)   \n",
       "2                                            experts     (288,295)   \n",
       "3  Jennifer Grygiel, a Syracuse University commun...     (491,586)   \n",
       "4  Jennifer Grygiel, a Syracuse University commun...     (491,586)   \n",
       "\n",
       "         verb   verb_index  \n",
       "0        said  (1247,1251)  \n",
       "1  announcing      (73,83)  \n",
       "2       noted    (296,301)  \n",
       "3        said    (587,591)  \n",
       "4        said    (587,591)  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the outcome into a pandas dataframe\n",
    "quotes_df = pd.DataFrame.from_dict(all_quotes)\n",
    "\n",
    "# re-arrange the columns\n",
    "new_index = ['quote_id', 'quote', 'quote_index', 'quote_token_count', 'quote_type','is_floating_quote', \n",
    "             'speaker', 'speaker_index', 'verb', 'verb_index']\n",
    "quotes_df = quotes_df.reindex(columns=new_index)\n",
    "\n",
    "# preview the quotes dataframe\n",
    "quotes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40d177a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save into an Excel spreadsheet\n",
    "quotes_df.to_excel('./output/quotes.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
